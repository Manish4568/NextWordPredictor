<!DOCTYPE html>
<!-- saved from url=(0039)https://nexttwordpredictorrr.anvil.app/ -->
<html lang="en" class="js anvil-runner runner sizes customelements history pointerevents postmessage postmessage-structuredclones webgl websockets cssanimations csscolumns csscolumns-width csscolumns-span csscolumns-fill csscolumns-gap csscolumns-rule csscolumns-rulecolor csscolumns-rulestyle csscolumns-rulewidth csscolumns-breakbefore csscolumns-breakafter csscolumns-breakinside flexbox picture srcset webworkers"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--<base href="https://nexttwordpredictorrr.anvil.app/">--><base href=".">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="expires" content="0">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="referrer" content="never"> <!-- Yes, this is "legacy", but Safari and Edge don't support 'no-referrer' yet -->

  <meta name="og:title" content="Custom HTML 1">
  <meta name="title" content="Custom HTML 1">
  <meta name="og:type" content="website">
  <meta name="og:url" content="https://nexttwordpredictorrr.anvil.app">
  <meta name="og:image" content="https://anvil.works/img/logo-square-padded.png">
  <!--<xmeta name="og:image:width" content="400">-->
  <!--<xmeta name="og:image:height" content="400">-->
  <!--<xmeta name="og:site_name" content="Anvil">-->
  <meta name="og:description" content="This app is built with Anvil, the platform for building full-stack web apps quickly and robustly.">
  <meta name="description" content="This app is built with Anvil, the platform for building full-stack web apps quickly and robustly.">


  <title>Custom HTML 1</title>

  <!-- <link rel="stylesheet" href="https://nexttwordpredictorrr.anvil.app/_/static/runtime/css/bootstrap.css?sha=adc8ee1e2b08f322404a" crossorigin/> -->
  <!-- <link rel="stylesheet" href="https://nexttwordpredictorrr.anvil.app/_/static/runtime/css/bootstrap-theme.min.css?sha=f2e1cc227d6bbb4192e4" crossorigin/> -->
  <style>
  .anvil-spinner{width:70px;height:70px}
  .anvil-spinner{color:#2ab1eb}
  </style>
  <link rel="stylesheet" href="./nwp_files/bootstrap.css" crossorigin="">
<link rel="stylesheet" href="./nwp_files/bootstrap-theme.min.css" crossorigin="">
<link rel="stylesheet" href="./nwp_files/animate.min.css" crossorigin="">
  <link rel="stylesheet" href="./nwp_files/runner.min.css" crossorigin="">
  <link rel="stylesheet" href="./nwp_files/runner-v3.min.css" crossorigin="">
  <link rel="stylesheet" href="./nwp_files/daterangepicker.min.css" crossorigin="">
  <!-- <link rel="stylesheet" href="https://nexttwordpredictorrr.anvil.app/_/static/runtime/node_modules/animate.css/animate.min.css?sha=8fe3fa119255adb5e0c1" crossorigin/> -->

  <link rel="stylesheet" href="./nwp_files/font-awesome.min.css" crossorigin="">

  <!-- Favicon things -->
  <link rel="icon" href="https://anvil.works/favicon-96x96.png">
  <link rel="manifest" href="https://nexttwordpredictorrr.anvil.app/_/manifest.json?buildTime=0">
  <link rel="apple-touch-icon" href="https://anvil.works/img/logo-square-padded.png">
  <meta name="apple-mobile-web-app-title" content="Custom HTML 1">
  <meta name="application-name" content="Custom HTML 1">
  <meta name="msapplication-TileColor" content="#2b5797">
  <meta name="msapplication-TileImage" content="https://anvil.works/mstile-144x144.png">
  <meta name="theme-color" content="#2ab1eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">

  <style></style>
  <style>:root {
}</style>
  
<style>

</style>


  <script src="./nwp_files/jquery.min.js.download" crossorigin=""></script>
  <script src="./nwp_files/jquery-migrate.min.js.download" crossorigin=""></script>

  
</head>
<body class="anvil-show-banner">
<div id="anvil-header">
  <a href="https://anvil.works/?utm_source=app_banner" target="_blank" class="cta"><span class="anvil-banner-hidden-xs">Build web apps for free with</span><span class="anvil-banner-xs">Built with</span> Anvil</a>
  <a href="https://anvil.works/?utm_source=app_banner" target="_blank"><span class="anvil-banner-hidden-xs">Built with </span><img src="./nwp_files/logo-35.png" crossorigin=""></a>
</div>

<a id="anvil-badge" href="https://anvil.works/?utm_source=app_banner" target="_blank">
  <img src="./nwp_files/made-with-anvil.png" crossorigin="">
</a>

<div class="anvil-root-container"><div id="appGoesHere"><div class="html-templated-panel anvil-container anvil-always-inline-container anvil-component has-components"><center style="font-style:italic; color:#888; margin: 3em;">
  (Insert your custom HTML here)
</center>
<div anvil-slot="default" class="anvil-inline-container"><div class="align-center anvil-spacing-above-small anvil-spacing-below-small left-icon has-text anvil-label anvil-inlinable anvil-component" style="text-align: center; font-size: 40px; font-weight: bold; font-style: italic; text-decoration: underline;"><i class="anvil-component-icon left  left-icon"></i><span class="label-text" style="text-decoration: underline;">Word Predictor</span><i class="anvil-component-icon right  left-icon"></i></div><div class="align-left anvil-spacing-above-large anvil-spacing-below-small left-icon has-text anvil-label anvil-inlinable anvil-component" style="text-align: left; font-size: 20px; font-style: italic; text-decoration: underline;"><i class="anvil-component-icon left  left-icon"></i><span class="label-text" style="text-decoration: underline;">Enter the Text Here:</span><i class="anvil-component-icon right  left-icon"></i></div><textarea class="anvil-text-area form-control to-disable align-left anvil-spacing-above-small anvil-spacing-below-small anvil-component" placeholder="" style="text-align: left; height: 80.4px;"></textarea><div class="align-left anvil-spacing-above-small anvil-spacing-below-small left-icon has-text anvil-label anvil-inlinable anvil-component" style="text-align: left; font-style: italic; text-decoration: underline;"><i class="anvil-component-icon left  left-icon"></i><span class="label-text" style="text-decoration: underline;">Enter Limit of Texts:</span><i class="anvil-component-icon right  left-icon"></i></div><input class="form-control to-disable anvil-text-box align-left anvil-spacing-above-small anvil-spacing-below-small anvil-component" type="text" placeholder="" style="text-align: left;"><div class="align-center anvil-spacing-above-medium anvil-spacing-below-small left-icon has-text anvil-inlinable anvil-button anvil-component" style="text-align: center;"><button class="btn btn-default to-disable" ontouchstart="" style="max-width: 100%; text-overflow: ellipsis; overflow: hidden; font-weight: bold;"><i class="anvil-component-icon left  left-icon"></i><span class="button-text">Predict</span><i class="anvil-component-icon right  left-icon"></i></button></div><div class="align-left anvil-spacing-above-small anvil-spacing-below-small left-icon has-text anvil-label anvil-inlinable anvil-component" style="text-align: left;"><i class="anvil-component-icon left  left-icon"></i><span class="label-text">Predicted Texts:</span><i class="anvil-component-icon right  left-icon"></i></div><div class="align-left anvil-spacing-above-small anvil-spacing-below-small anvil-rich-text anvil-inlinable anvil-container anvil-component" style="text-align: left; white-space: unset;"></div></div></div></div></div>

<div id="loadingSpinner" class="anvil-spinner" style="display: none; opacity: 0;">
    <svg class="anvil-spinner-svg" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><style>@keyframes anvil-chase{to{transform: rotate(360deg)}}@keyframes anvil-chase-dot{80%,to{transform: rotate(360deg)}}@keyframes anvil-scale-dot{0%,100%{transform: scale(1)}50%{transform: scale(.4)}}.anvil-spinner-g circle{transform-origin: 12px 2.5px;animation: anvil-scale-dot 2s ease-in-out infinite}.anvil-spinner-g &gt; g{transform-origin: center;animation: anvil-chase-dot 2s ease-in-out infinite}.anvil-spinner-svg{fill:currentColor;stroke:currentColor}</style><g class="anvil-spinner-g" style="transform-origin:center;animation:anvil-chase 2.5s infinite linear both"><g style="animation-delay:-1.1s"><circle cx="12" cy="2.5" r="1.5" style="animation-delay:-1.1s"></circle></g><g style="animation-delay:-1s"><circle cx="12" cy="2.5" r="1.5" style="animation-delay:-1s"></circle></g><g style="animation-delay:-.9s"><circle cx="12" cy="2.5" r="1.5" style="animation-delay:-.9s"></circle></g><g style="animation-delay:-.8s"><circle cx="12" cy="2.5" r="1.5" style="animation-delay:-.8s"></circle></g><g style="animation-delay:-.7s"><circle cx="12" cy="2.5" r="1.5" style="animation-delay:-.7s"></circle></g><g style="animation-delay:-.6s"><circle cx="12" cy="2.5" r="1.5" style="animation-delay:-.6s"></circle></g></g></svg>
</div>


<div id="error-indicator">
  <div style="float:left; width: 40px">
    <i class="glyphicon glyphicon-warning-sign" style="float:left; width: 40px;"></i>
  </div>
  <div style="float:right;">
    <a class="glyphicon glyphicon-remove" href="https://nexttwordpredictorrr.anvil.app/#" onclick="$(&#39;#error-indicator&#39;).hide(); return false;"></a>
  </div>
  <div class="headline">This app has experienced an error</div>
  <div class="message">Click for more information</div>
  <pre class="output"></pre>
  <div style="clear:both"></div>
</div>
<script>
  (function () {
    const spinner = document.getElementById("loadingSpinner");
    const getBgImage = (pseudo) => getComputedStyle(spinner, pseudo).backgroundImage;
    for (const pseudo of [undefined, "::after", "::before"]) {
        if (getBgImage(pseudo) !== "none") {
            const svg = spinner.querySelector("svg")
            svg && svg.style.setProperty("display", "none");
            return;
        }
    }
  }());
</script>

<script src="./nwp_files/modernizr-3.8.0.min.js.download" crossorigin=""></script>

<!--<script src="https://nexttwordpredictorrr.anvil.app/_/static/runtime/node_modules/bootstrap/dist/js/bootstrap.min.js?sha=9ee2fcff6709e4d0d24b" crossorigin></script>-->
<script src="./nwp_files/bootstrap.min.js.download" crossorigin=""></script>
<script src="./nwp_files/moment.min.js.download" crossorigin=""></script>
<script src="./nwp_files/moment-timezone-with-data-2012-2022.min.js.download" crossorigin=""></script>
<script src="./nwp_files/daterangepicker.min.js.download" crossorigin=""></script>
<script src="./nwp_files/b64.js.download" crossorigin=""></script>
<script src="./nwp_files/bootstrap-notify.min.js.download" crossorigin=""></script>

<script src="./nwp_files/js-yaml.min.js.download" crossorigin=""></script>

<!--   <script src="https://nexttwordpredictorrr.anvil.app/_/static/runtime/node_modules/core-js-bundle/minified.js?sha=90d19e92b7cd38fee6c8" crossorigin></script>
 -->

<script src="./nwp_files/skulpt.min.js.download" crossorigin=""></script>
<script src="./nwp_files/skulpt-stdlib.js.download" crossorigin=""></script>

<script src="./nwp_files/runner2.bundle.js.download" crossorigin=""></script>


<script>
  window.anvilCDNOrigin = "https://anvil.works/runtime-new";
  window.anvilAppOrigin = "https://nexttwordpredictorrr.anvil.app";
  window.anvilEnvironmentOrigin = "https://nexttwordpredictorrr.anvil.app";
  window.anvilSessionToken = "Y5PU7KL6WLIMBW6K4JPKVWXLSBKW65DG=iueRO7P3WaxUiY7f6z_NChN0PNiA";
  window.anvilVersion = "187a1dd7937e6ae99e5f8ea62a9dce635681a2fe";
  window.anvilAppInfo = {"id":"EPQKLGEWOQYLAQFS","branch":"master","environment":{"description":"Default Environment","tags":null}};
  window.anvilGoogleApiKey = "AIzaSyCn8yc8dmMNcmAn-e_K5HT7NX19csXUGUA";
  // docker-platform-server-base script adds sha's in html files - we put this variable here so that we can aggrissively cache the std-lib files
  // the std-lib is loaded dynamically in runner.js
  window.anvilSkulptLib = {
    1: "https://nexttwordpredictorrr.anvil.app/_/static/runtime/js/lib/skulpt-stdlib-1.json?sha=a402eb8840d2b2160634",
    2: "https://nexttwordpredictorrr.anvil.app/_/static/runtime/js/lib/skulpt-stdlib-2.json?sha=733be17e0f599eeeea1d",
    3: "https://nexttwordpredictorrr.anvil.app/_/static/runtime/js/lib/skulpt-stdlib-3.json?sha=5a72749d3007fec4b08b"
  };

  {
    // remove _anvil_session to prevent referrer links from including the session
    const url = new URL(window.location.href);
    url.searchParams.delete("_anvil_session");
    window.history.replaceState(window.history.state || {}, "Anvil App", url);
  }

  // 
$(function() {Sk.builtinFiles.files["anvil-services\/tables\/__init__.py"] = "from anvil.tables import *\nfrom anvil.tables import _page_size\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/__init__.py"] = "import time\n\nimport anvil.server\n\nfrom ._base_classes import Row, SearchIterator, Table\nfrom . import _config\nfrom ._errors import NoSuchColumnError, QuotaExceededError, RowDeleted, TableError, TransactionConflict\nfrom ._helpers import _hash_wrapper\n\n# Use old app tables by default\nclass AppTables(object):\n    cache = None\n\n    def __getattr__(self, name):\n        if AppTables.cache is None:\n            AppTables.cache = anvil.server.call(\"anvil.private.tables.get_app_tables\")\n\n        tbl = AppTables.cache.get(name)\n        if tbl is not None:\n            return tbl\n\n        raise AttributeError(\"No such app table: '%s'\" % name)\n\n    def __setattr__(self, name, val):\n        raise Exception(\"app_tables is read-only\")\n    \n    def __iter__(self):\n        return AppTableIterator()\n    \n\nclass AppTableIterator:\n    def __init__(self):\n        self._it = None\n\n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        # because __iter__ can't suspend\n        if AppTables.cache is None:\n            AppTables.cache = anvil.server.call(\"anvil.private.tables.get_app_tables\")\n        if self._it is None:\n            self._it = AppTables.cache.keys().__iter__()\n        return next(self._it)\n    \n    next = __next__\n\n\n_set_class = object.__dict__[\"__class__\"].__set__\n\ndef _lazy_replace_class(self):\n    if _config.get_client_config().get(\"enable_v2\"):\n        from . import v2\n        v2._app_tables._clear_cache()\n        _set_class(self, type(v2.app_tables))\n    else:\n        AppTables.cache = None\n        _set_class(self, AppTables)\n\n\n\ndef _wrap_dunder(method):\n    def wrapped(self, *args, **kws):\n        _lazy_replace_class(self)\n        return getattr(self, method)(*args, **kws)\n\n    return wrapped\n\n\nclass _LazyAppTables(object):\n    def __getattribute__(self, name):\n        _lazy_replace_class(self)\n        return getattr(self, name)\n\n    __setattr__ = _wrap_dunder(\"__setattr__\")\n    __getitem__ = _wrap_dunder(\"__getitem__\")\n    __dir__ = _wrap_dunder(\"__dir__\")\n    __iter__ = AppTables.__iter__\n\n\nclass _LazyContext(object):\n    def __enter__(self):\n        global batch_update, batch_delete\n        if not _config.get_client_config().get(\"enable_v2\"):\n            batch_update.__class__ = batch_delete.__class__ = type(None)\n            return self.__enter__()\n\n        from .v2 import _batcher as _b\n\n        for obj, orig in zip((batch_update, batch_delete), (\"batch_update\", \"batch_delete\")):\n            obj.__class__ = type(getattr(_b, orig))\n            obj.__init__()\n            setattr(_b, orig, obj)\n        return self.__enter__()\n\n    def __exit__(self, *args):\n        assert not isinstance(self, _LazyContext)\n        return self.__exit__(*args)\n\n\ndef _clear_cache():\n    _config.reset_config()\n    _set_class(app_tables, _LazyAppTables)\n\n\nanvil.server._on_invalidate_client_objects(_clear_cache)\n\n\n#!defModuleAttr(anvil.tables)!1:\n# {\n# \tname: \"app_tables\",\n# \ttype: \"any\",\n# \tanvil$helpLink: \"\/docs\/data-tables\/data-tables-in-code\",\n# \t$doc: \"Access Table objects from the datatables services. You can access a Table object with dot notation e.g. `app_tables.my_table`. To access a table with strings use `getattr(app_tables, 'my_table')`. If no table is present an AttributeError will be thrown.\"\n# }\n#\napp_tables = _LazyAppTables()\nbatch_update = _LazyContext()\nbatch_delete = _LazyContext()\n# Not very nice but these references exist in uplink code\n# before we have a chance to know if we're using the v1\/v2 config option\n# we can't call anvil.server until the uplink has made a connetion\n\n\ndef get_table_by_id(table_id):\n    if _config.get_client_config().get(\"enable_v2\"):\n        from .v2 import get_table_by_id\n\n        return get_table_by_id(table_id)\n    raise TableError(\"get_table_by_id is only available in Accelerated Tables beta\")\n\n\n#!defModuleAttr(anvil.tables)!1:\n# {\n# \tname: \"app_tables\",\n# \ttype: \"any\",\n# \tanvil$helpLink: \"\/docs\/data-tables\/data-tables-in-code\",\n# \t$doc: \"Access Table objects from the datatables services. You can access a Table object with dot notation e.g. `app_tables.my_table`. To access a table with strings use `getattr(app_tables, 'my_table')`. If no table is present an AttributeError will be thrown.\"\n# }\n#\n\n\nclass Transaction:\n    def __init__(self, relaxed=False):\n        self._aborting = False\n        self._isolation = \"relaxed\" if relaxed else None\n\n    #!defMethod(anvil.tables.Transaction instance)!2: \"Begin the transaction\" [\"__enter__\"]\n    def __enter__(self):\n        anvil.server.call(\"anvil.private.tables.open_transaction\", isolation=self._isolation)\n        return self\n\n    #!defMethod(_)!2: \"End the transaction\" [\"__exit__\"]\n    def __exit__(self, e_type, e_val, tb):\n        anvil.server.call(\"anvil.private.tables.close_transaction\", self._aborting or e_val is not None)\n\n    #!defMethod(_)!2: \"Abort this transaction. When it ends, all write operations performed during it will be cancelled\" [\"abort\"]\n    def abort(self):\n        self._aborting = True\n\n\n#!defClass(anvil.tables,%Transaction)!:\n\n\n#!defFunction(anvil.tables,%,function,server_function)!2:\n# {\n# \t$doc: \"When applied to a function (as a decorator), the whole function will run in a data tables transaction. If it conflicts with another transaction, it will retry up to five times.\",\n# anvil$helpLink: \"\/docs\/data-tables\/transactions\"\n#  } [\"in_transaction\"]\ndef in_transaction(maybe_f=None, relaxed=None):\n    # we don't want to import this on the client unnecessarily\n    import functools\n\n    def wrap(f):\n        @functools.wraps(f)\n        def new_f(*args, **kwargs):\n            n = 0\n            while True:\n                try:\n                    with Transaction(relaxed=relaxed):\n                        return f(*args, **kwargs)\n                except TransactionConflict:\n                    # lazy load random incase we make random.js a slow path on the client\n                    import random\n\n                    n += 1\n                    if n == 18:\n                        raise\n                    # print(f\"RETRYING TXN {n}\")\n                    # Max total sleep time is a little under 150 seconds (avg 75), so server calls will timeout before this finishes usually.\n                    sleep_amt = random.random() * (1.5**n) * 0.05\n                    try:\n                        time.sleep(sleep_amt)\n                    except:\n                        anvil.server.call(\"anvil.private._sleep\", sleep_amt)\n\n        try:\n            reregister = f._anvil_reregister\n        except AttributeError:\n            pass\n        else:\n            reregister(new_f)\n\n        return new_f\n\n    if maybe_f is None:\n        return wrap\n    else:\n        return wrap(maybe_f)\n\n\n#!defFunction(anvil.tables,_,column_name,ascending=)!2: \"Sort the results of this table search by a particular column. Default to ascending order.\" [\"order_by\"]\n@anvil.server.portable_class\nclass order_by(object):\n    def __init__(self, column_name, ascending=True):\n        self.column_name = column_name\n        self.ascending = ascending\n\n    __hash__, __eq__ = _hash_wrapper(\"column_name\", \"ascending\")\n\n\n# backward compatability\nfrom .query import fetch_only\nfrom .query import page_size as _page_size\n\n\n#!defFunction(anvil.tables,%,[via_host=],[via_port=])!2: \"Get a Postgres connection string for accessing this app's Data Tables via SQL.\\n\\nThe returned string includes temporary login credentials and sets the search path to a schema representing this app's Data Table environment.\\n\\nYou can override the host and port for the database connection to connect via a secure tunnel.\\n\\n(Available on the Dedicated Plan only.)\" [\"get_connection_string\"]\ndef get_connection_string(via_host=None, via_port=None):\n    return anvil.server.call(\n        \"anvil.private.get_direct_postgres_connection_string\", via_host=via_host, via_port=via_port\n    )\n\n\n#!defMethod(table row, **column_values)!2: \"Add a row to the data table. Use keyword arguments to specify column values.\" [\"add_row\"]\n#!defMethod(client readable view)!2: \"Return a view on the table that can be read by client code. Use keyword arguments to specify view restrictions\" [\"client_readable\"]\n#!defMethod(client writable view)!2: \"Return a view on the table that can be written by client code. Use keyword arguments to specify view restrictions. This does not give the client write access to other tables referred to by the table.\" [\"client_writable\"]\n#!defMethod(client writable view)!2: \"Return a view on this table that can be written by client code. Use keyword arguments to specify view restrictions.\" [\"client_writable_cascade\"]\n#!defMethod(_)!2: \"Delete all the rows from the data table\" [\"delete_all_rows\"]\n#!defMethod(_)!2: \"Get a single matching row from the data table whose columns match the keyword arguments. Returns None if no matching row exists, and raises an exception if more than one row matches.\\n\\nEg: app_tables.table_1.get(name='John Smith')\" [\"get\"]\n#!defMethod(row,id)!2: \"Get the matching row from this data table, by its unique ID\" [\"get_by_id\"]\n#!defMethod(bool,row)!2: \"Returns true if the table (or view) contains the provided row.\" [\"has_row\"]\n#!defMethod(list of dicts)!2: \"Get the spec for the table as a list of dicts. Each dict contains the name and type of a column.\" [\"list_columns\"]\n#!defMethod(Row or None)!2: \"Get rows from a data table. If you specify keyword arguments, you will retrieve only rows whose columns match those values.\\n\\nEg: app_tables.table_1.search(name='John Smith')\" [\"search\"]\n#!defMethod(Media object, [escape_for_excel=False])!2: \"Get the table in CSV format, optionally escaped for use in Excel. Returns a downloadable Media object; use its url property.\" [\"to_csv\"]\n#!defClassNoConstructor(anvil.tables,#Table)!1: \"A table returned from app_tables\"\n\n#!defMethod(Media object, [escape_for_excel=False])!2: \"Get the results of the SearchIterator in CSV format, optionally escaped for use in Excel. Returns a downloadable Media object; use its url property.\" [\"to_csv\"]\n#!defClassNoConstructor(anvil.tables,#SearchIterator)!1: \"An iterator of table rows returned from a search()\";\n\n\n#!defMethod(_)!2: \"Delete the row from its data table\" [\"delete\"]\n#!defMethod(id)!2: \"Get the unique ID of the table row\" [\"get_id\"]\n#!defMethod(_,**column_values)!2: \"update the data for multiple columns\" [\"update\"]\n#!defClassNoConstructor(anvil.tables,#Row)!1: \"A table row\";\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/query.py"] = "from anvil.server import portable_class\n\nfrom ._helpers import _hash_wrapper\n\n# Don't load v2 code unless v2 is imported. v2._load_hacks will inject this for us.\n# from .v2._refs import make_refs as _make_refs\n_make_refs = lambda x: x\n\n\n\n\nclass _pattern_query(object):\n    def __init__(self, pattern):\n        self.pattern = pattern\n\n    __hash__, __eq__ = _hash_wrapper(\"pattern\")\n\n\nclass _value_query(object):\n    def __init__(self, value):\n        self.value = value\n\n    __hash__, __eq__ = _hash_wrapper(\"value\")\n\n\nclass _of_query(object):\n    def __init__(self, *args, **kwargs):\n        self.args = _make_refs(args)\n        self.kwargs = _make_refs(kwargs)\n\n    def __hash__(self):\n        return hash(self.args + tuple(sorted(self.kwargs.items())))\n\n    def __eq__(self, other):\n        if type(other) is not type(self):\n            return NotImplemented\n        return self.args == other.args and self.kwargs == other.kwargs\n\n\n#!defFunction(anvil.tables.query,_,pattern)!2: \"Match values using a case-sensitive LIKE query, using the % wildcard character.\" [\"like\"]\n@portable_class\nclass like(_pattern_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,pattern)!2: \"Match values using a case-insensitive ILIKE query, using the % wildcard character.\" [\"ilike\"]\n@portable_class\nclass ilike(_pattern_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,value)!2: \"Match values greater than the provided value.\" [\"greater_than\"]\n@portable_class\nclass greater_than(_value_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,value)!2: \"Match values less than the provided value.\" [\"less_than\"]\n@portable_class\nclass less_than(_value_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,value)!2: \"Match values greater than or equal to the provided value.\" [\"greater_than_or_equal_to\"]\n@portable_class\nclass greater_than_or_equal_to(_value_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,value)!2: \"Match values less than or equal to the provided value.\" [\"less_than_or_equal_to\"]\n@portable_class\nclass less_than_or_equal_to(_value_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,min,max,[min_inclusive=True],[max_inclusive=False])!2: \"Match values between the provided min and max, optionally inclusive.\" [\"between\"]\ndef between(min, max, min_inclusive=True, max_inclusive=False):\n    return all_of(\n        greater_than_or_equal_to(min) if min_inclusive else greater_than(min),\n        less_than_or_equal_to(max) if max_inclusive else less_than(max),\n    )\n\n\n#!defFunction(anvil.tables.query,_,query,[raw=False])!2: \"Match values that match the provided full-text search query.\" [\"full_text_match\"]\n@portable_class\nclass full_text_match(object):\n    def __init__(self, query, raw=False):\n        self.query = query\n        self.raw = raw\n\n    __hash__, __eq__ = _hash_wrapper(\"query\", \"raw\")\n\n\n#!defFunction(anvil.tables.query,_,*query_expressions)!2: \"Match all query parameters given as arguments and keyword arguments\" [\"all_of\"]\n@portable_class\nclass all_of(_of_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,*query_expressions)!2: \"Match any query parameters given as arguments and keyword arguments\" [\"any_of\"]\n@portable_class\nclass any_of(_of_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,*query_expressions)!2: \"Match none of the query parameters given as arguments and keyword arguments\" [\"none_of\"]\n@portable_class\nclass none_of(_of_query):\n    pass\n\n\n#!defFunction(anvil.tables.query,_,*query_expressions)!2: \"Match none of the query parameters given as arguments and keyword arguments\" [\"not_\"]\nnot_ = none_of\n\n#!defFunction(anvil.tables.query,_,rows)!2: \"Define the number of rows that are fetched per round trip to the server.\" [\"page_size\"]\n@portable_class\nclass page_size(object):\n    def __init__(self, rows):\n        self.rows = rows\n\n    __hash__, __eq__ = _hash_wrapper(\"rows\")\n\n\n@portable_class(\"anvil.tables.fetch_only\")\nclass fetch_only(object):\n    def __init__(self, *only_cols, **linked_cols):\n        spec = {}\n        for col in only_cols:\n            if not isinstance(col, str):\n                raise TypeError(\"columns must be strings\")\n            spec[col] = True\n        for col, only in linked_cols.items():\n            if not isinstance(only, fetch_only):\n                raise TypeError(\"keyword arguments must use q.fetch_only()\")\n            spec[col] = only.spec\n        self.spec = spec\n\n    def _hashable(self, val):\n        if val is True:\n            return val\n        return self._as_tuple(val)\n\n    def _as_tuple(self, spec):\n        return tuple((col_name, self._hashable(val)) for col_name, val in sorted(spec.items()))\n\n    def __hash__(self):\n        return hash(self._as_tuple(self.spec))\n\n    def __eq__(self, other):\n        if type(other) is not type(self):\n            return NotImplemented\n        return other.spec == self.spec\n\n\n@portable_class\nclass only_cols(object):\n    def __init__(self, *cols):\n        self.cols = tuple(sorted(cols))\n\n    __hash__, __eq__ = _hash_wrapper(\"cols\")\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/_helpers.py"] = "def _hash_wrapper(*params):\n    # this makes query objects cachable as keys of dictionaries\n    def _mk_tuple(self):\n        return tuple(getattr(self, param) for param in params)\n\n    def __hash__(self):\n        return hash(_mk_tuple(self))\n\n    def __eq__(self, other):\n        if type(other) is not type(self):\n            return NotImplemented\n        return _mk_tuple(self) == _mk_tuple(other)\n\n    return __hash__, __eq__\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/_errors.py"] = "import anvil.server\n\n\n#!defMethod()!2: \"Superclass of all table exceptions\" [\"__init__\"]\n#!defClass(anvil.tables,TableError,__builtins__..Exception)!:\nclass TableError(anvil.server.AnvilWrappedError):\n    pass\n\n\n#!defMethod()!2: \"Raised when attempting to accessing a table row that has been deleted - for example, accessing a row after calling its delete() method, or following a link to a deleted row.\" [\"__init__\"]\n#!defClass(anvil.tables,RowDeleted,anvil.tables.TableError)!:\nclass RowDeleted(TableError):\n    pass\n\n\n#!defMethod()!2: \"Raised when attempting to access a column that does not exist in this table.\" [\"__init__\"]\n#!defClass(anvil.tables,NoSuchColumnError,anvil.tables.TableError)!:\nclass NoSuchColumnError(TableError):\n    pass\n\n\n#!defMethod()!2: \"Raised when a transaction conflicts and has been aborted.\" [\"__init__\"]\n#!defClass(anvil.tables,TransactionConflict,anvil.tables.TableError)!:\nclass TransactionConflict(TableError):\n    pass\n\n\n#!defMethod()!2: \"Raised when an app has exceeded its quota.\" [\"__init__\"]\n#!defClass(anvil.tables,QuotaExceededError,anvil.tables.TableError)!:\nclass QuotaExceededError(TableError):\n    pass\n\n\nanvil.server._register_exception_type(\"anvil.tables.TransactionConflict\", TransactionConflict)\nanvil.server._register_exception_type(\"anvil.tables.TableError\", TableError)\nanvil.server._register_exception_type(\"anvil.tables.RowDeleted\", RowDeleted)\nanvil.server._register_exception_type(\"anvil.tables.NoSuchColumnError\", NoSuchColumnError)\nanvil.server._register_exception_type(\"anvil.tables.QuotaExceededError\", QuotaExceededError)\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/_config.py"] = "import anvil\n\n_config = None\n\n\ndef get_client_config():\n    global _config\n    if _config is not None:\n        return _config\n    _config = anvil._get_service_client_config(\"\/runtime\/services\/tables.yml\") or {}\n    return _config\n\ndef reset_config():\n    global _config\n    _config = None";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/_base_classes.py"] = "class AppTables(object):\n    def __repr__(self):\n        return \"<anvil.tables.{} object>\".format(type(self).__name__)\n\n\nclass AbstractTableClass(object):\n    _instead = None\n\n    def __init__(self, *args, **kwargs):\n        raise TypeError(\"Can't instantiate a {} object. Use {} instead.\".format(type(self).__name__, self._instead))\n\n    def __repr__(self):\n        return \"<anvil.tables.{} object>\".format(type(self).__name__)\n\n    def __dir__(self):\n        # TODO should we keep this?\n        # remove private attributes and methods from the dir\n        return [key for key in object.__dir__(self) if (not key.startswith(\"_\")) or key.startswith(\"__\")]\n\n\nclass Table(AbstractTableClass):\n    _instead = \"app_tables.my_table\"\n\n\nclass SearchIterator(AbstractTableClass):\n    _instead = \"app_tables.my_table.search()\"\n\n\nclass Row(AbstractTableClass):\n    _instead = \"app_tables.my_table.add_row()\"\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/__init__.py"] = "from .._base_classes import Row, SearchIterator, Table\nfrom . import _load_hacks\nfrom ._app_tables import app_tables, get_table_by_id\n\n# from ._batcher import batch_delete, batch_update\n\n__all__ = [\"app_tables\", \"get_table_by_id\"]\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_app_tables.py"] = "import anvil.server\n\nfrom .._base_classes import AppTables as BaseAppTables\nfrom ._constants import SERVER_PREFIX\nfrom ._table import Table\n\n_table_cache = None\n\n\ndef _fill_cache():\n    global _table_cache\n    if _table_cache is None:\n        _table_cache = anvil.server.call(SERVER_PREFIX + \"get_app_tables\")\n    return _table_cache\n\n\ndef _clear_cache():\n    global _table_cache\n    _table_cache = None\n\n\nclass AppTableIterator:\n    def __init__(self):\n        self._it = None\n\n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        if self._it is None:\n            self._it = _fill_cache().__iter__()\n        return next(self._it)\n    \n    next = __next__\n\n\nclass AppTables(BaseAppTables):\n    def __getattribute__(self, name):\n        # use __getattribute__ so that we prioritise the table name\n        try:\n            return self[name]\n        except KeyError:\n            return object.__getattribute__(self, name)\n\n    def __getitem__(self, name):\n        cache = _fill_cache()\n        table_args = cache[name]\n        return Table._create(*table_args)\n\n    def __setattr__(self, name, val):\n        raise AttributeError(\"app_tables is read-only\")\n\n    def __dir__(self):\n        return object.__dir__(self) + list(_fill_cache().keys())\n    \n    def __iter__(self):\n        return AppTableIterator()\n\n\n\ndef get_table_by_id(table_id):\n    table_args = anvil.server.call(SERVER_PREFIX + \"get_table_by_id\", table_id)\n    return table_args and Table._create(*table_args)\n\n\napp_tables = AppTables()\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_batcher.py"] = "import anvil.server\n\nfrom ._constants import SERVER_PREFIX, NOT_FOUND\n\nPREFIX = SERVER_PREFIX + \"row.\"\n_make_refs = None  # Circular import\n\n\nclass _Batcher:\n    _name = \"\"\n    _instance = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = object.__new__(cls)\n        return cls._instance\n\n    def __init__(self):\n        self._active = False\n        self._updates = []\n        self._buffer = {}\n        self._func = PREFIX + self._name\n\n    @property\n    def active(self):\n        return self._active\n\n    def push(self, cap, update=False):\n        self._updates.append((cap, update))\n\n    def reset(self):\n        self._active = False\n        self._updates.clear()\n        self._buffer.clear()\n\n    def __enter__(self):\n        if self._active:\n            raise RuntimeError(\"nested batching is not suppported\")\n        self._active = True\n\n    def get_args(self, updates):\n        raise NotImplementedError\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        updates = self._updates\n        try:\n            if exc_value is None and updates:\n                anvil.server.call(self._func, self.get_args(updates))\n                for cap, update in updates:\n                    cap.send_update(update)\n        finally:\n            self.reset()\n\n\nclass BatchUpdate(_Batcher):\n    _name = \"batch_update\"\n\n    def push(self, cap, update):\n        self._updates.append((cap, update))\n        self._buffer.setdefault(cap, {}).update(update)\n\n    def get_updates(self, cap):\n        return self._buffer.get(cap, {})\n\n    def read(self, cap, key):\n        return self.get_updates(cap).get(key, NOT_FOUND)\n\n    def get_args(self, updates):\n        global _make_refs\n        if _make_refs is None:\n            from ._refs import make_refs  # circular import\n\n            _make_refs = make_refs\n\n        return [(cap, _make_refs(update)) for cap, update in updates]\n\n\nclass BatchDelete(_Batcher):\n    _name = \"batch_delete\"\n\n    def get_args(self, updates):\n        return [cap for cap, _ in updates]\n\n\nbatch_update = BatchUpdate()\nbatch_delete = BatchDelete()\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_constants.py"] = "import anvil.server\n\n# USED as an argument to the \"create_view\" private method\nREAD = \"r\"\nWRITE = \"rw\"\nCASCADE = \"rwc\"\nKNOWN_PERMS = (READ, WRITE, CASCADE)\n\nNOT_FOUND = object()\nCAP_KEY = \"c\"\n\nSINGLE = \"link_single\"\nMULTIPLE = \"link_multiple\"\nDATETIME = \"datetime\"\nMEDIA = \"media\"\n\nSHARED_DATA_KEY = \"anvil.tables\"\n\nSERVER_PREFIX = \"anvil.private.tables.v2.\"\n\n\n@anvil.server.portable_class(\"anvil.tables.v2.UNCACHED\")\nclass _UncachedType(object):\n    _instance = None\n\n    def __new__(cls):\n        self = cls._instance\n        if self is None:\n            cls._instance = self = object.__new__(cls)\n        return self\n\n    def __repr__(self):\n        return \"UNCACHED\"\n\n    @classmethod\n    def __new_deserialized__(cls, data, info):\n        return UNCACHED\n\n    def __serialize__(self, info):\n        return None\n\n\nUNCACHED = _UncachedType()\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_load_hacks.py"] = "# For the sake of a soft roll-out, we don't want to load v2 code implicitly\n# from anvil.tables.query, but that module needs access to `make_refs` if we're\n# using v2. So we inject it (only) when v2 loads.\n\nfrom .. import query\nfrom . import _refs\n\nquery._make_refs = _refs.make_refs\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_refs.py"] = "from anvil.server import portable_class\n\nfrom ._row import Row\n\n# Helpful classes for table methods that include Rows\/SearchIterators\n# But sending the Row across the wire is unnecessary\n# We shouldn't be deserializing these objects but we include __deserialize__ for completeness\n\n\nclass _Ref(object):\n    def __init__(self, cap):\n        self.cap = cap\n\n    def __hash__(self):\n        return hash(self.cap)\n\n    def __serialize__(self, info):\n        return self.cap\n\n    def __deserialize__(self, cap, info):\n        self.cap = cap\n\n    def __eq__(self, other):\n        if type(self) is not type(other):\n            return NotImplemented\n        return self.cap == other.cap\n\n\n@portable_class(\"anvil.tables.v2._RowRef\")\nclass RowRef(_Ref):\n    pass\n\n\n@portable_class\nclass SearchIteratorRef(_Ref):\n    pass\n\n\ndef to_ref(obj):\n    ob_type = type(obj)\n    if ob_type in (list, tuple):\n        return tuple(to_ref(item) for item in obj)\n    elif ob_type is Row:\n        return RowRef(obj._cap)\n    return obj\n\n\ndef make_refs(args_or_kws):\n    if type(args_or_kws) is dict:\n        return {key: to_ref(val) for key, val in args_or_kws.items()}\n    else:\n        return tuple(to_ref(val) for val in args_or_kws)\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_row.py"] = "import anvil.server\r\nfrom anvil.server import Capability\r\n\r\nfrom .._base_classes import Row as BaseRow\r\nfrom .._errors import NoSuchColumnError, RowDeleted, TableError\r\nfrom . import _batcher\r\nfrom ._constants import CAP_KEY, DATETIME, MEDIA, MULTIPLE, NOT_FOUND, SERVER_PREFIX, SHARED_DATA_KEY, SINGLE, UNCACHED\r\nfrom ._utils import check_serialized, clean_local_datetime, init_spec_rows, init_view_data, merge_row_data, validate_cap\r\n\r\nPREFIX = SERVER_PREFIX + \"row.\"\r\n_make_refs = None  # for circular imports\r\n_auto_create_is_enabled = NOT_FOUND\r\n\r\n\r\ndef _copy(so):\r\n    if type(so) is list:\r\n        return [_copy(o) for o in so]\r\n    if type(so) is dict:\r\n        return {k: _copy(v) for k, v in so.items()}\r\n    return so\r\n\r\n\r\n@anvil.server.portable_class\r\nclass Row(BaseRow):\r\n    @classmethod\r\n    def _create(cls, view_key, table_id, row_id, spec=None, cap=None):\r\n        row = object.__new__(cls)\r\n        row._view_key = view_key\r\n        row._table_id = table_id\r\n        row._id = row_id\r\n        row._cap = cap\r\n        row._cache = {}\r\n        row._spec = spec  # None when we are deserialized without access to table_data\r\n        row._cache_spec = spec[\"cache\"] if spec is not None else []\r\n        row._has_uncached = True\r\n        row._exists = True\r\n        row._dirty_spec = False  # used for serialization\r\n        if cap is not None:\r\n            cap.set_update_handler(row._cap_update_handler)\r\n        return row\r\n\r\n    @classmethod\r\n    def _create_from_untrusted(cls, view_key, table_id, row_id, cap, local_data):\r\n        # check that we can trust the data that was sent!\r\n        row = local_data.get(cap)\r\n        if row is None:\r\n            row = local_data[cap] = cls._create(view_key, table_id, row_id, None, cap)\r\n        return row\r\n\r\n    @classmethod\r\n    def _create_from_trusted(cls, view_key, table_id, row_id, table_data):\r\n        table_id, row_id = str(table_id), str(row_id)\r\n        view_data = table_data[view_key]\r\n        rows = view_data[\"rows\"]\r\n        row_data = rows[row_id]\r\n        if isinstance(row_data, Row):\r\n            # prevent circular and use the created row from view_data\r\n            return row_data\r\n        spec = view_data[\"spec\"]\r\n        row = rows[row_id] = cls._create(view_key, table_id, row_id, spec)\r\n        # Replace the compact row_data with ourself\r\n        # This prevents circular references and has the benefit that\r\n        # we create the same rows and linked rows when creating Row objects from the same data\r\n        row._unpack(table_data, row_data)\r\n        if view_data.get(\"dirty_spec\"):\r\n            # a serialized row marked its spec as dirty after an update\r\n            row._clear_cache()\r\n        return row\r\n\r\n    @classmethod\r\n    def _create_from_local_values(cls, view_key, table_id, row_id, spec, cap, local_items):\r\n        # the basic idea here is that we need to clean datetime objects and UNCACHE any linked rows\r\n        # where the view_key doesn't match what we expect from the col_spec\r\n        table_id, row_id = str(table_id), str(row_id)\r\n        row = cls._create(view_key, table_id, row_id, spec, cap)\r\n        clean_items = row._walk_local_items(local_items, missing=None)\r\n        row._cache.update(clean_items)\r\n        row._check_has_cached()\r\n        return row\r\n\r\n    # DESERIALIZE\r\n    @classmethod\r\n    def __new_deserialized__(cls, data, info):\r\n        table_data, local_data = info.shared_data(SHARED_DATA_KEY)\r\n        view_key, table_id, row_id, cap = data\r\n        if not info.remote_is_trusted:\r\n            validate_cap(cap, table_id, row_id)\r\n            table_data = None  # just incase\r\n        if not table_data:\r\n            # table_data None is not enough because we may be sending rows back and forward\r\n            # i.e. passing from client to server to client goes untrusted -> trusted -> client\r\n            return cls._create_from_untrusted(view_key, table_id, row_id, cap, local_data)\r\n        return cls._create_from_trusted(view_key, table_id, row_id, table_data)\r\n\r\n    def _unpack(self, table_data, row_data):\r\n        assert type(row_data) in (list, dict), \"Unable to create Row object, bad row_data\"\r\n        spec = table_data[self._view_key][\"spec\"]\r\n        if self._spec is None:\r\n            self._spec = spec\r\n        cols = spec[\"cols\"] if spec is not None else []\r\n        initial_load = not bool(self._cache)\r\n        row_data_type = type(row_data)\r\n        # if the spec is None we must have a dict data type with a single cap key\r\n        # this potentially happens in (and is enforced by) serialization\r\n        if row_data_type is list:\r\n            unpacked_cache, cap = self._unpack_compact(table_data, spec, cols, row_data, initial_load)\r\n        elif row_data_type is dict:\r\n            unpacked_cache, cap = self._unpack_dict(table_data, cols, row_data, initial_load)\r\n        else:\r\n            raise TableError(\"the row data is invalid\")\r\n\r\n        assert type(cap) is Capability, \"invalid row_data\"\r\n        if self._cap is None:\r\n            self._cap = cap\r\n            cap.set_update_handler(self._cap_update_handler)\r\n        self._cache.update(unpacked_cache)\r\n        self._check_has_cached()\r\n\r\n    def _unpack_compact(self, table_data, spec, cols, row_data, initial_load):\r\n        # spec[\"cache\"] 1s matches the len(row_data) (+cap)\r\n        iter_row_data = iter(row_data)\r\n        unpacked_cache = {}\r\n        for col, is_cached in zip(cols, spec[\"cache\"]):\r\n            if is_cached:\r\n                val = self._unpack_linked(next(iter_row_data), col, table_data)\r\n            elif initial_load:\r\n                val = UNCACHED  # there's nothing there yet so fill it\r\n            else:\r\n                continue\r\n            unpacked_cache[col[\"name\"]] = val\r\n        return unpacked_cache, next(iter_row_data)\r\n\r\n    def _unpack_dict(self, table_data, cols, row_data, initial_load):\r\n        unpacked_cache = {}\r\n        for i, col in enumerate(cols):\r\n            val = row_data.pop(str(i), UNCACHED)\r\n            if val is UNCACHED and not initial_load:\r\n                # does this ever happen?\r\n                continue\r\n            unpacked_cache[col[\"name\"]] = self._unpack_linked(val, col, table_data)\r\n        cap = row_data.pop(CAP_KEY, None)\r\n        assert len(row_data) == 0, \"Invalid row data\"\r\n        return unpacked_cache, cap\r\n\r\n    def _unpack_linked(self, val, col, table_data):\r\n        table_id = col.get(\"table_id\")\r\n        if table_id is None or val is UNCACHED or val is None:\r\n            # not a linked row, or UNCACHED linked row (serialize cache dispute), or linked row is None\r\n            return val\r\n        col_type, view_key = col[\"type\"], col[\"view_key\"]\r\n        if col_type == SINGLE:\r\n            row_id = val\r\n            return Row._create_from_trusted(view_key, table_id, row_id, table_data)\r\n        elif col_type == MULTIPLE:\r\n            row_ids = val\r\n            return [Row._create_from_trusted(view_key, table_id, row_id, table_data) for row_id in row_ids]\r\n\r\n        raise AssertionError(\"bad col type with table_id\")\r\n\r\n    # SERIALIZATION\r\n    def __serialize__(self, info):\r\n        table_data, local_data = info.shared_data(SHARED_DATA_KEY)\r\n        if table_data is not None and info.local_is_trusted:\r\n            self._merge_and_reduce(table_data, local_data)\r\n        return [self._view_key, self._table_id, self._id, self._cap]\r\n\r\n    def _merge_linked(self, val, col, g_table_data, local_data):\r\n        type = col[\"type\"]\r\n        if val is UNCACHED or val is None:\r\n            # maybe we were serialized and converted linked row(s) to UNCACHED\r\n            # or actually the linked row is None\r\n            pass\r\n        elif type == SINGLE:\r\n            row = val\r\n            val = row._merge_and_reduce(g_table_data, local_data)\r\n        elif type == MULTIPLE:\r\n            val = [row._merge_and_reduce(g_table_data, local_data) for row in val]\r\n        return val\r\n\r\n    def _make_row_data(self, g_table_data, local_data, cache_spec):\r\n        table_spec = self._spec\r\n        table_cols = table_spec[\"cols\"] if table_spec is not None else []\r\n        cache = self._cache\r\n        # we can't rely on the order of cache in python 2\r\n        cached_data = []\r\n        for i, (col, is_cached) in enumerate(zip(table_cols, cache_spec)):\r\n            if not is_cached:\r\n                continue\r\n            name = col[\"name\"]\r\n            val = self._merge_linked(cache[name], col, g_table_data, local_data)\r\n            cached_data.append((i, val))\r\n        cached_data.append((CAP_KEY, self._cap))\r\n        return cached_data\r\n\r\n    def _merge_and_reduce(self, g_table_data, local_data):\r\n        if check_serialized(self, local_data):\r\n            return int(self._id)\r\n        g_view_data = init_view_data(self._view_key, g_table_data)\r\n        table_spec, row_id, cache_spec = self._spec, self._id, self._cache_spec\r\n\r\n        # We assert that there is no way for rows from the same view_key to have different col_specs\r\n        # This includes the order\r\n        # the only thing they may differ on is cache_specs\r\n        g_table_spec, g_table_rows = init_spec_rows(g_view_data, table_spec, cache_spec)\r\n        g_cache_spec = g_table_spec[\"cache\"] if g_table_spec is not None else None\r\n\r\n        if table_spec is not None and g_cache_spec is not None:\r\n            is_dirty = self._dirty_spec or len(cache_spec) != len(g_cache_spec)\r\n        else:\r\n            is_dirty = self._dirty_spec\r\n\r\n        if is_dirty:\r\n            g_view_data[\"dirty_spec\"] = True\r\n            cache_spec = []\r\n\r\n        cached_data = self._make_row_data(g_table_data, local_data, cache_spec)\r\n        existing = g_table_rows.get(row_id, [])\r\n\r\n        if not is_dirty and cache_spec == g_cache_spec and type(existing) is list:\r\n            row_data = [val for _, val in cached_data]\r\n        else:\r\n            row_data = {str(key): val for key, val in cached_data}\r\n\r\n        merge_row_data(row_id, row_data, g_table_rows, g_table_spec, cache_spec)\r\n        return int(row_id)\r\n\r\n    # PRIVATE METHODS\r\n    def _cap_update_handler(self, updates):\r\n        if updates is False:\r\n            # We've been deleted clear_cache so that\r\n            # server calls are required for data access\r\n            self._clear_cache()\r\n            self._exists = False\r\n            return\r\n        elif self._spec is None:\r\n            return\r\n        clean_items = self._walk_local_items(updates)\r\n        self._cache.update(clean_items)\r\n        self._check_has_cached()\r\n\r\n    def _check_has_cached(self):\r\n        if self._spec is None:\r\n            return\r\n        self._cache_spec = [int(self._cache[col[\"name\"]] is not UNCACHED) for col in self._spec[\"cols\"]]\r\n        self._has_uncached = any(val is UNCACHED for val in self._cache.values())\r\n\r\n    def _clear_cache(self):\r\n        # clearing the cache also clears the spec - this forces a call to the server to update a spec\r\n        self._spec = None\r\n        self._cache.clear()\r\n        self._cache_spec = []\r\n        self._has_uncached = True\r\n\r\n    def _fill_cache(self, fetch=None):\r\n        if fetch is not None:\r\n            uncached_keys = None if fetch is True else fetch\r\n        elif self._spec is None:\r\n            uncached_keys = None\r\n        elif self._has_uncached:\r\n            uncached_keys = [key for key, val in self._cache.items() if val is UNCACHED]\r\n        else:\r\n            return  # no uncached values\r\n\r\n        table_data = anvil.server.call(PREFIX + \"fetch\", self._cap, uncached_keys)\r\n        rows = table_data[self._view_key][\"rows\"]\r\n        row_data = rows[self._id]\r\n        # Replace the compact row data with this Row instance\r\n        # so circular references don't clobber the data while we're unpacking.\r\n        rows[self._id] = self\r\n        self._unpack(table_data, row_data)\r\n\r\n    def _walk_local_items(self, items, missing=NOT_FOUND):\r\n        # We are about to put local items in the cache\r\n        # so check linked rows have valid view keys datetimes have tz.offset applied\r\n        items = items.copy()\r\n        rv = {}\r\n        cols = self._spec[\"cols\"]\r\n        for col in cols:\r\n            name, type = col[\"name\"], col[\"type\"]\r\n            val = items.pop(name, missing)\r\n            if val is NOT_FOUND:\r\n                continue\r\n            else:\r\n                rv[name] = _copy(val)\r\n            if val is UNCACHED or val is None:\r\n                continue\r\n            elif type == DATETIME:\r\n                rv[name] = clean_local_datetime(val)\r\n                continue\r\n            elif type == MEDIA:\r\n                rv[name] = UNCACHED  # we need to fetch a lazy media with a valid url\r\n                continue\r\n            elif type == SINGLE:\r\n                val = [val]\r\n            elif type != MULTIPLE:\r\n                continue\r\n            rows = val\r\n            expected_view_key = col[\"view_key\"]\r\n            if any(row._view_key != expected_view_key for row in rows):\r\n                rv[name] = UNCACHED\r\n        if len(items):\r\n            # more items than we should have - our col spec is no good anymore\r\n            self._dirty_spec = True\r\n            rv.update(items)\r\n        return rv\r\n\r\n    def _check_exists(self):\r\n        # only call this if we're not doing a server call\r\n        if not self._exists:\r\n            raise RowDeleted(\"This row has been deleted\")\r\n\r\n    # DUNDER METHODS\r\n    def __iter__(self):\r\n        # call to __iter__ can't suspend\r\n        # so only do suspension stuff in __next__\r\n        # note that this will not get called for dict(row)\r\n        # keys() and __getitem__ wins for a call to dict\r\n        return RowIterator(self)\r\n\r\n    def __contains__(self, key):\r\n        return key in self.keys()\r\n\r\n    def __getitem__(self, key):\r\n        if not isinstance(key, str):\r\n            raise TypeError(\"Row columns are always strings, not {}\".format(type(key).__name__))\r\n        if _batcher.batch_update.active:\r\n            rv = _batcher.batch_update.read(self._cap, key)\r\n            if rv is not NOT_FOUND:\r\n                return _copy(rv)\r\n        if self._spec is None:\r\n            self._fill_cache()\r\n        hit = self._cache.get(key, NOT_FOUND)\r\n        if hit is UNCACHED:\r\n            # we have a spec now so we'll fetch the remaining columns\r\n            self._fill_cache()\r\n        elif hit is NOT_FOUND:\r\n            global _auto_create_is_enabled\r\n            if _auto_create_is_enabled is NOT_FOUND:\r\n                _auto_create_is_enabled = anvil.server.call(PREFIX + \"can_auto_create\")\r\n            if _auto_create_is_enabled:\r\n                # try to force fetch this key - incase we have a bad spec - i.e auto-columns\r\n                self._fill_cache([key])\r\n        else:\r\n            return _copy(hit)\r\n        try:\r\n            return _copy(self._cache[key])\r\n        except KeyError:\r\n            raise NoSuchColumnError(\"No such column '\" + key + \"'\")\r\n\r\n    def __setitem__(self, key, value):\r\n        return self.update(**{key: value})\r\n\r\n    def __eq__(self, other):\r\n        if not isinstance(other, Row):\r\n            return NotImplemented\r\n        return other._id == self._id and other._table_id == self._table_id\r\n\r\n    def __hash__(self):\r\n        self._check_exists()\r\n        return hash((self._table_id, self._id))\r\n\r\n    def __repr__(self):\r\n        if self._spec is None:\r\n            return \"<anvil.tables.Row object>\"\r\n\r\n        # custom reprs depending on type\r\n        trunc_str = lambda s: repr(s) if len(s) < 20 else repr(s[:17] + \"...\")\r\n        dt_repr = lambda d: \"datetime(\" + str(d) + \")\"\r\n        d_repr = lambda d: \"date(\" + str(d) + \")\"\r\n        printable_types = {\"string\": trunc_str, \"bool\": repr, \"date\": d_repr, \"datetime\": dt_repr, \"number\": repr}\r\n\r\n        # Find cols that are both cached and easily printed\r\n        cache, cols = self._cache, self._spec[\"cols\"]\r\n        cached_printable_cols = [\r\n            (c[\"name\"], printable_types[c[\"type\"]], cache[c[\"name\"]])\r\n            for c in cols\r\n            if c[\"type\"] in printable_types and cache[c[\"name\"]] is not UNCACHED\r\n        ]\r\n        # Only keep the first 5\r\n        cached_printable_cols = cached_printable_cols[:5]\r\n        # Find all the remaining columns\r\n        num_remaning = len(cols) - len(cached_printable_cols)\r\n\r\n        vals = \", \".join(\r\n            \"{}={}\".format(name, None if val is None else meth(val)) for name, meth, val in cached_printable_cols\r\n        )\r\n\r\n        if not num_remaning:\r\n            and_more = \"\"\r\n        elif cached_printable_cols:\r\n            and_more = \", plus {} more column{}\".format(num_remaning, \"s\" if num_remaning != 1 else \"\")\r\n        else:\r\n            and_more = \"{} column{}\".format(num_remaning, \"s\" if num_remaning != 1 else \"\")\r\n\r\n        return \"<anvil.tables.Row: {}{}>\".format(vals, and_more)\r\n\r\n    # PUBLIC API\r\n    # deprecated\r\n    def get_id(self):\r\n        # For compatibility with LiveObjects\r\n        self._check_exists()\r\n        return \"[{},{}]\".format(self._table_id, self._id)\r\n\r\n    # TODO reinclude this api\r\n    # @property\r\n    # def id(self):\r\n    #     return self._id\r\n\r\n    # TODO reinclude this api\r\n    # @property\r\n    # def table_id(self):\r\n    #     return self._table_id\r\n\r\n    def get(self, key, default=None):\r\n        try:\r\n            return self[key]\r\n        except NoSuchColumnError:\r\n            return default\r\n\r\n\r\n    def keys(self):\r\n        if self._spec is None:\r\n            # if we don't have a _spec we don't have any keys\r\n            # but we don't need to blindly call _fill_uncached: UNCACHED values are fine\r\n            self._fill_cache()\r\n        return self._cache.keys()\r\n\r\n    def _get_view(self):\r\n        self._fill_cache()\r\n        view = _copy(self._cache)\r\n        if _batcher.batch_update.active:\r\n            batched = _batcher.batch_update.get_updates(self._cap)\r\n            view.update(_copy(batched))\r\n        return view\r\n\r\n    def items(self):\r\n        return self._get_view().items()\r\n\r\n    def values(self):\r\n        return self._get_view().values()\r\n\r\n    def update(*args, **new_items):\r\n        # avoid name conflicts with columns, could use (self, other, \/, **kws)\r\n        # but positioin only args not available in py2\/Skulpt\r\n        if not args:\r\n            raise TypeError(\"method 'update' of 'Row' object needs an argument\")\r\n        elif len(args) > 2:\r\n            raise TypeError(\"expected at most 1 argument, got %d\" % (len(args) - 1))\r\n        elif len(args) == 2:\r\n            new_items = dict(args[1], **new_items)\r\n        self = args[0]\r\n        if not new_items:\r\n            # backwards compatability hack\r\n            self._clear_cache()\r\n            return\r\n\r\n        # circular reference\r\n        if _batcher.batch_update.active:\r\n            return _batcher.batch_update.push(self._cap, new_items)\r\n\r\n        global _make_refs\r\n        if _make_refs is None:\r\n            from ._refs import make_refs  # circular import\r\n\r\n            _make_refs = make_refs\r\n\r\n        anvil.server.call(PREFIX + \"update\", self._cap, _make_refs(new_items))\r\n        self._cap.send_update(new_items)\r\n\r\n    def delete(self):\r\n        if _batcher.batch_delete.active:\r\n            return _batcher.batch_delete.push(self._cap)\r\n\r\n        anvil.server.call(PREFIX + \"delete\", self._cap)\r\n        self._cap.send_update(False)\r\n\r\n    def refresh(self, fetch=None):\r\n        if fetch is not None:\r\n            from ..query import fetch_only\r\n\r\n            if not isinstance(fetch, fetch_only):\r\n                raise TypeError(\"the second argument to refresh should be a q.fetch_only() object\")\r\n            fetch = fetch.spec\r\n        self._clear_cache()\r\n        self._fill_cache(fetch)\r\n\r\n\r\nclass RowIterator:\r\n    def __init__(self, row):\r\n        self._row = row\r\n        self._fill_required = row._spec is None\r\n        self._iter = iter(row._cache.items())\r\n\r\n    def __iter__(self):\r\n        return self\r\n\r\n    def __next__(self):\r\n        if self._fill_required:\r\n            self._row._fill_cache()\r\n            self.__init__(self._row)\r\n\r\n        key, value = next(self._iter)\r\n        if value is UNCACHED:\r\n            # fill the rest of the cache\r\n            # since we probably want all the items!\r\n            # we rely here on the _cache keys not changing during iteration\r\n            # which works since we've filled it with UNCACHED values that match our expected keys\r\n            self._row._fill_cache()\r\n            value = self._row._cache[key]\r\n\r\n        if _batcher.batch_update.active:\r\n            batched = _batcher.batch_update.read(self._row._cap, key)\r\n            if batched is not NOT_FOUND:\r\n                value = batched\r\n\r\n        return (key, _copy(value))\r\n\r\n    next = __next__\r\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_search.py"] = "import anvil.server\nfrom anvil.server import Capability\n\nfrom .._base_classes import SearchIterator as BaseSearchIterator\nfrom ._constants import CAP_KEY, SERVER_PREFIX, SHARED_DATA_KEY\nfrom ._row import Row\nfrom ._utils import check_serialized, init_spec_rows, init_view_data, merge_row_data, validate_cap\n\nPREFIX = SERVER_PREFIX + \"search.\"\n\n\nclass PartialSearchIter(object):\n    def __init__(self, s, slice_):\n        self._view_key = s._view_key\n        self._table_id = s._table_id\n        self._cap = s._cap\n        self._idx = slice_.start or 0\n        self._step = slice_.step or 1\n        self._stop = slice_.stop\n        row_ids, cap_next = s._row_ids, s._cap_next\n        if row_ids is None:\n            # this can happen in deserialization from untrusted\/None transmited data\n            row_ids, cap_next = [], s._cap\n        assert cap_next is None or type(cap_next) is Capability\n        self._reset(row_ids, cap_next, s._table_data)\n\n    def _reset(self, row_ids, cap_next, table_data):\n        if self._stop is not None and len(row_ids) > self._stop:\n            row_ids, cap_next = row_ids[: self._stop], None\n        self._row_ids = row_ids\n        self._cap_next = cap_next\n        self._table_data = table_data\n\n    def _iter_next_page(self):\n        if self._cap_next is None:\n            raise StopIteration\n\n        num_row_ids = len(self._row_ids)\n        self._idx -= num_row_ids\n        if self._stop is not None:\n            self._stop -= num_row_ids\n\n        row_ids, cap_next, table_data = anvil.server.call(PREFIX + \"next_page\", self._cap_next)\n\n        self._reset(row_ids, cap_next, table_data)\n        return self.__next__()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            row_id = self._row_ids[self._idx]\n        except IndexError:\n            return self._iter_next_page()\n        self._idx += self._step\n        return Row._create_from_trusted(self._view_key, self._table_id, row_id, self._table_data)\n\n    next = __next__\n\n\n@anvil.server.portable_class\nclass SearchIterator(BaseSearchIterator):\n    @classmethod\n    def _create(cls, view_key, table_id, row_ids, cap, cap_next, table_data):\n        self = object.__new__(cls)\n        assert cap_next is None or type(cap_next) is Capability\n        self._view_key = view_key\n        self._table_id = table_id\n        self._row_ids = row_ids\n        self._cap = cap\n        self._cap_next = cap_next\n        self._table_data = table_data\n        self._from_serialize = False\n        return self\n\n    @classmethod\n    def __new_deserialized__(cls, data, info):\n        view_key, table_id, row_ids, cap, cap_next = data\n        table_data, _ = info.shared_data(SHARED_DATA_KEY)\n        if not info.remote_is_trusted:\n            validate_cap(cap, table_id)\n            table_data = None\n        if not table_data:\n            row_ids = cap_next = None\n        # when we deserialize ourselves we may have more data than we need\n        self = cls._create(view_key, table_id, row_ids, cap, cap_next, table_data)\n        self._from_serialize = True\n        return self\n\n    def _fill_data(self):\n        self._row_ids, self._cap_next, self._table_data = anvil.server.call(PREFIX + \"next_page\", self._cap)\n\n    def _clear_cache(self):\n        self._row_ids = self._table_data = self._cap_next = None\n\n    # SERIALIZATION\n    def _make_row_data(self, row_data, table_spec, compact=True):\n        if type(row_data) is dict or compact:\n            # this row didn't match our cache_spec so just send it\n            # or we are list and we're compact because our cache_specs already match\n            return row_data\n\n        cache_spec = table_spec[\"cache\"]\n        # we are currently compact and we need to be a dict\n        new_data = {CAP_KEY: row_data[-1]}\n        iter_row_data = iter(row_data)\n\n        new_data = {str(i): next(iter_row_data) for i, is_cached in enumerate(cache_spec) if is_cached}\n        cap = next(iter_row_data)\n        assert type(cap is Capability)\n        new_data[CAP_KEY] = cap\n        return new_data\n\n    def _get_table_view_iter(self):\n        if not self._from_serialize:\n            # Fast Path - we were created from my_table.search() so the table_data is already minimal\n            # i.e. we don't need to clean it based on table_specs\n            return self._table_data.keys()\n\n        # Slow Path - we're reserializing ourselves from a previous serialization\n        # so we may have too much data if we were serialized with merged table_data\n        table_view_keys = set()\n        # walk the table_specs and insert the view_keys and table_ids we need\n        _populate_table_views_ids(self._view_key, self._table_data, table_view_keys)\n        return table_view_keys\n\n    def _merge(self, g_table_data, local_data):\n        if check_serialized(self, local_data):\n            return\n\n        table_view_keys = self._get_table_view_iter()\n\n        for view_key in table_view_keys:\n            g_view_data = init_view_data(view_key, g_table_data)\n            l_view_data = self._table_data[view_key]\n\n            l_table_spec, l_table_rows = l_view_data[\"spec\"], l_view_data.get(\"rows\", {})\n            g_table_spec, g_table_rows = init_spec_rows(g_view_data, l_table_spec)\n\n            g_cache_spec = g_table_spec[\"cache\"]\n            l_cache_spec = l_table_spec[\"cache\"]\n            cache_match = g_table_spec is l_table_spec or g_cache_spec == l_cache_spec\n\n            for row_id, row_data in l_table_rows.items():\n                if isinstance(row_data, Row):\n                    # Ok we've already been created\n                    # this is rare - we've consumed the search iterator and now we're serializing\n                    # or we created this row from shared serialization data and we're now reserializing\n                    row = row_data\n                    row._merge_and_reduce(g_table_data, local_data)\n                    continue\n\n                g_row_data = g_table_rows.get(row_id, [])\n                g_is_compact = cache_match and type(g_row_data) is list\n                row_data = self._make_row_data(row_data, l_table_spec, compact=g_is_compact)\n                merge_row_data(row_id, row_data, g_table_rows, g_table_spec, l_cache_spec)\n\n    def __serialize__(self, info):\n        table_data, local_data = info.shared_data(SHARED_DATA_KEY)\n        row_ids = self._row_ids\n        if table_data is None:\n            row_ids = self._cap_next = None\n        elif info.local_is_trusted and self._table_data is not None:\n            self._merge(table_data, local_data)\n        return [self._view_key, self._table_id, row_ids, self._cap, self._cap_next]\n\n    def _make_partial_iterator(self, slice_=slice(None)):\n        return PartialSearchIter(self, slice_)\n\n    def __iter__(self):\n        return self._make_partial_iterator()\n\n    def __len__(self):\n        if self._cap_next is None and self._row_ids is not None:\n            return len(self._row_ids)\n        return anvil.server.call(PREFIX + \"get_length\", self._cap)\n\n    def __hash__(self):\n        return hash((self._table_id, self._cap))\n\n    def __eq__(self, other):\n        if not isinstance(other, SearchIterator):\n            return NotImplemented\n        return self._cap == other._cap\n\n    def __bool__(self):\n        # because we have a __len__ and we can't suspend\n        return True\n\n    __nonzero__ = __bool__\n\n    def refresh(self):\n        self._clear_cache()\n\n    def to_csv(self, escape_for_excel=False):\n        return anvil.server.call(PREFIX + \"to_csv\", self._cap, escape_for_excel=escape_for_excel)\n\n    def delete_all_rows(self):\n        result = anvil.server.call(PREFIX + \"delete_all\", self._cap)\n        self._clear_cache()\n        return result\n\n    def __getitem__(self, idx):\n        if self._row_ids is None:\n            self._fill_data()\n\n        if isinstance(idx, slice):\n            slice_ = slice(as_slice_idx(idx.start), as_slice_idx(idx.stop), as_slice_idx(idx.step))\n            return self._make_partial_iterator(slice_)\n        else:\n            slice_ = slice(as_idx(idx), None)\n        try:\n            return next(self._make_partial_iterator(slice_))\n        except StopIteration:\n            raise IndexError(\"search index out of range\")\n\n\ndef as_idx(i, msg=\"search indices must be non-negative integers\", can_be_none=False):\n    if i is None and can_be_none:\n        return None\n    elif type(i) is int:\n        pass\n    elif hasattr(i, \"__index__\"):\n        i = i.__index__()\n    else:\n        raise TypeError(msg)\n    if i < 0:\n        raise ValueError(msg)\n    return i\n\n\ndef as_slice_idx(i):\n    msg = \"search slice indices must non-negative itegers (or None)\"\n    return as_idx(i, msg, True)\n\n\ndef _populate_table_views_ids(view_key, table_data, seen):\n    # We might hold too much data if our table_data was from another serialization\n    # If we're reserializing ourselves then this method prevents sending unnecessary data across the wire\n    if view_key in seen:\n        # prevent circular references\n        return\n\n    try:\n        table_spec = table_data[view_key][\"spec\"]\n    except KeyError:\n        # Then these linked rows were not included in the data - probably uncached from the cache spec\n        # don't try include this view_key when serializing the data\n        return\n\n    seen.add(view_key)\n    cols = table_spec[\"cols\"]\n\n    for col in cols:\n        view_key = col.get(\"view_key\")\n        if view_key is None:\n            continue\n        _populate_table_views_ids(view_key, table_data, seen)\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_table.py"] = "import anvil.server\nfrom anvil.server import Capability\n\nfrom .._base_classes import Table as BaseTable\nfrom ._constants import CASCADE, KNOWN_PERMS, READ, SERVER_PREFIX, WRITE\nfrom ._refs import make_refs\nfrom ._row import Row\nfrom ._search import SearchIterator\nfrom ._utils import validate_cap\n\nPREFIX = SERVER_PREFIX + \"table.\"\n\n\n@anvil.server.portable_class\nclass Table(BaseTable):\n    @classmethod\n    def _create(cls, cap, view_key, table_id):\n        assert cap is None or type(cap) is Capability, \"expected a table capability\"\n        self = object.__new__(cls)\n        self._cap = cap\n        self._view_key = view_key\n        self._id = str(table_id)\n        return self\n\n    @classmethod\n    def __new_deserialized__(cls, data, info):\n        cap, view_key, table_id = data\n        if not info.remote_is_trusted:\n            validate_cap(cap, table_id)\n        return cls._create(cap, view_key, table_id)\n\n    def __serialize__(self, _info):\n        return [self._cap, self._view_key, self._id]\n\n    def __iter__(self):\n        raise TypeError(\"You can't iterate on a table. Call search() on this table to get an iterator of rows instead.\")\n\n    def __eq__(self, other):\n        if not isinstance(other, Table):\n            return NotImplemented\n        return other._id == self._id\n\n    def __hash__(self):\n        return hash(self._id)\n\n    def __contains__(self, row):\n        return self.has_row(row)\n\n    def _get_view(self, perm, args, kws):\n        assert perm in KNOWN_PERMS, \"bad permission\"\n        new_cap, view_key = anvil.server.call(\n            PREFIX + \"get_view\", self._cap, perm, None, make_refs(args), make_refs(kws)\n        )\n        return Table._create(new_cap, view_key, self._id)\n\n    # PUBLIC API\n    def restrict_columns(self, col_spec):\n        new_cap, view_key = anvil.server.call(\"get_restricted_columns\", self._cap, col_spec)\n        return Table._create(new_cap, view_key, self._id)\n\n    def client_readable(self, *args, **kws):\n        return self._get_view(READ, args, kws)\n\n    def client_writable(self, *args, **kws):\n        return self._get_view(WRITE, args, kws)\n\n    def client_writable_cascade(self, *args, **kws):\n        return self._get_view(CASCADE, args, kws)\n\n    def delete_all_rows(self):\n        return anvil.server.call(PREFIX + \"delete_all_rows\", self._cap)\n\n    def add_rows(self, rows):\n        # rows can be an iterable of dicts\n        row_dicts = []\n        refs = []\n        for row in rows:\n            row = dict(row)\n            refs.append(make_refs(row))\n            row_dicts.append(row)\n        row_id_caps, spec = anvil.server.call(PREFIX + \"add_rows\", self._cap, refs)\n        return [\n            Row._create_from_local_values(self._view_key, self._id, row_id, spec, cap, row_items)\n            for (row_id, cap), row_items in zip(row_id_caps, row_dicts)\n        ]\n\n    def add_row(self, **data):\n        row_id, cap, spec = anvil.server.call(PREFIX + \"add_row\", self._cap, make_refs(data))\n        return Row._create_from_local_values(self._view_key, self._id, row_id, spec, cap, data)\n\n    def get(self, *args, **kws):\n        row_id_table_data = anvil.server.call(PREFIX + \"get_row\", self._cap, make_refs(args), make_refs(kws))\n        return row_id_table_data and Row._create_from_trusted(self._view_key, self._id, *row_id_table_data)\n\n    def get_by_id(self, row_id, fetch=None):\n        row_id_table_data = anvil.server.call(PREFIX + \"get_row_by_id\", self._cap, row_id, fetch=fetch)\n        return row_id_table_data and Row._create_from_trusted(self._view_key, self._id, *row_id_table_data)\n\n    def has_row(self, row):\n        if not isinstance(row, Row):\n            # backwards compatability return False\n            return False\n        elif row._table_id != self._id:\n            return False\n        return anvil.server.call(PREFIX + \"has_row\", self._cap, row._id)\n\n    def list_columns(self):\n        return anvil.server.call(PREFIX + \"list_columns\", self._cap)\n\n    def search(self, *args, **kws):\n        kws = make_refs(kws)\n        row_ids, cap, cap_next, table_data = anvil.server.call(PREFIX + \"search\", self._cap, args, kws)\n        return SearchIterator._create(self._view_key, self._id, row_ids, cap, cap_next, table_data)\n\n    def to_csv(self, escape_for_excel=False):\n        return anvil.server.call(PREFIX + \"to_csv\", self._cap, escape_for_excel=escape_for_excel)\n\n    # TODO reinclude this API\n    # @property\n    # def id(self):\n    #     return self._id\n";Sk.builtinFiles.files["anvil-services\/anvil\/tables\/v2\/_utils.py"] = "import anvil.tz\nfrom anvil.server import Capability, unwrap_capability\n\nfrom ._constants import CAP_KEY, NOT_FOUND, UNCACHED\n\n\ndef validate_cap(cap, table_id, row_id=NOT_FOUND):\n    # this function ensures that the cap is the right shape and references the right table\/row\n    # full validation happens in clojure\n    _, _, view_dict, narrowed, _ = unwrap_capability(cap, [\"_\", \"t\", Capability.ANY, Capability.ANY, Capability.ANY])\n    assert str(view_dict[\"id\"]) == table_id\n    if row_id is not NOT_FOUND:\n        assert row_id == str(narrowed[\"r\"])\n\n\ndef clean_local_datetime(d):\n    if d.tzinfo is not None:\n        offset = d.utcoffset().total_seconds()\n    else:\n        offset = anvil.tz.tzlocal().utcoffset(d).total_seconds()\n    return d.replace(tzinfo=anvil.tz.tzoffset(seconds=offset))\n\n\n# Serialization helpers\ndef check_serialized(self, local_data):\n    self_id = id(self)\n    serialized = local_data.get(self_id, False)\n    local_data[self_id] = True\n    return serialized\n\n\ndef init_view_data(view_key, g_table_data):\n    return g_table_data.setdefault(view_key, {})\n\n\ndef init_spec_rows(g_view_data, table_spec, cache_spec=None):\n    g_table_spec = g_view_data.get(\"spec\")\n    if g_table_spec is not None:\n        pass\n    elif table_spec is None or cache_spec is None:\n        g_table_spec = g_view_data[\"spec\"] = table_spec\n    else:\n        g_table_spec = g_view_data[\"spec\"] = {\"cols\": table_spec[\"cols\"], \"cache\": cache_spec}\n    g_table_rows = g_view_data.setdefault(\"rows\", {})\n    return g_table_spec, g_table_rows\n\n\ndef merge_row_data(row_id, row_data, g_table_rows, g_table_spec, row_cache_spec):\n    # we've already cleaned the row_data\n    #  - it will only be a compact list if the caches match\n    #  - and g_row_data is either None or also a compact list\n    # otherwise row_data will be a dict\n    g_row_data = g_table_rows.get(row_id)\n\n    # FAST - common case - nothing in row_data\n    if g_row_data is None:\n        g_table_rows[row_id] = row_data\n        return\n\n    g_row_type = type(g_row_data)\n    row_type = type(row_data)\n\n    # handle all UNCACHED - i.e. the partially cached writer wins\n    if g_row_type is list and len(g_row_data) == 1:\n        # the row serialized before us has an all 0 cache_spec and is compact\n        # we are either a dict or a list of the same length\n        g_table_rows[row_id] = row_data\n        return\n    if not any(row_cache_spec):\n        # the row to merge has an all 0 cache_spec\n        return\n\n    # SLOW PATH - uncommon cases\n    # Another reference to this row (not the exact same row) was already serialized before us\n    if row_type is list:\n        # g_row_data must also be a compact list if row_data is a list\n        # they must have the same length at this stage since we know the cache specs match\n        if g_row_type is list:\n            # fail safe sanity check\n            merge_compact(row_data, g_row_data)\n        \n    elif g_row_type is dict:\n        # then the previously serialized reference to this row\n        # didn't match the g_cache_spec\n        # so just take the itersect of the dictionaries\n        g_table_rows[row_id] = merge_dicts(row_data, g_row_data)\n        return\n    else:\n        # finally the g_row_type is a compact list and we are a dict - make it a dict\n        g_cache_spec = g_table_spec[\"cache\"]\n        merge_dict_with_compact(row_data, g_row_data, row_cache_spec, g_cache_spec)\n        g_table_rows[row_id] = row_data\n\n\ndef merge_compact(row_data, g_row_data):\n    # any conflicts just replace with UNCACHED sentinel\n    # use len - 1 so we skip the Capability\n    for i in range(len(row_data) - 1):\n        gbl, loc = g_row_data[i], row_data[i]\n        if gbl != loc:\n            g_row_data[i] = UNCACHED\n\n\ndef merge_dicts(row_data, g_row_data):\n    # walk the smallest\n    merged = {}\n    a, b = (row_data, g_row_data) if len(row_data) < len(g_row_data) else (g_row_data, row_data)\n    cap = a.pop(CAP_KEY)\n    for key, a_val in a.items():\n        b_val = b.get(key, NOT_FOUND)\n        if a_val == b_val:\n            merged[key] = a_val\n    merged[CAP_KEY] = a[CAP_KEY] = cap\n    return a\n\n\ndef merge_dict_with_compact(row_data, g_row_data, row_cache_spec, g_cache_spec):\n    iter_g_row_data = iter(g_row_data)\n    for i, (is_cached, g_is_cached) in enumerate(zip(row_cache_spec, g_cache_spec)):\n        i = str(i)\n        if not g_is_cached:\n            # we could use the incoming caller wins here\n            if is_cached:\n                row_data.pop(i, None)\n            continue\n\n        g_val = next(iter_g_row_data)\n        if not is_cached:\n            continue\n\n        if i in row_data and row_data[i] != g_val:\n            row_data.pop(i)\n\n    return row_data\n";const loadApp = window.loadApp({"app":{"allow_embedding":false,"dependency_code":{},"package_name":"Custom_HTML_1","config":{"client":{}},"modules":[],"name":"Custom HTML 1","dependency_ids":{},"startup_form":"Form1","dependency_order":[],"theme":{"html":{"standard-page.html":"<div anvil-slot-repeat=\"default\">\n<\/div>\n\n<center style=\"color:#888; margin: 50px;\">\n  <i>This is a placeholder for your app's custom HTML. Edit it by changing the theme assets.<\/i>\n<\/center>\n"},"color_scheme":{},"vars":{}},"runtime_options":{"version":2,"client_version":"3"},"forms":[{"container":{"type":"HtmlTemplate","properties":{"html":"<center style=\"font-style:italic; color:#888; margin: 3em;\">\n  (Insert your custom HTML here)\n<\/center>\n<div anvil-slot=\"default\"><\/div>"}},"components":[{"name":"label_1","properties":{"italic":true,"underline":true,"text":"Word Predictor","bold":true,"align":"center","font":"","font_size":40},"type":"Label","layout_properties":{"slot":"default"}},{"name":"label_2","properties":{"text":"Enter the Text Here:","italic":true,"underline":true,"font_size":20,"spacing_above":"large","spacing_below":"small"},"type":"Label","layout_properties":{"slot":"default"}},{"name":"text_area","properties":{"height":80.39996337890625},"type":"TextArea","layout_properties":{"slot":"default"}},{"name":"label_3","properties":{"text":"Enter Limit of Texts:","bold":false,"italic":true,"underline":true},"type":"Label","layout_properties":{"slot":"default"}},{"name":"limit_text","properties":{},"type":"TextBox","layout_properties":{"slot":"default"}},{"name":"button_1","properties":{"text":"Predict","bold":true,"spacing_above":"medium"},"type":"Button","layout_properties":{"slot":"default"},"event_bindings":{"click":"button_1_click"}},{"name":"label_4","properties":{"text":"Predicted Texts:"},"type":"Label","layout_properties":{"slot":"default"}},{"name":"rich_text_1","properties":{},"type":"RichText","layout_properties":{"slot":"default"}}],"is_package":true,"code":"from ._anvil_designer import Form1Template\nfrom anvil import *\nimport anvil.server\n\nclass Form1(Form1Template):\n  def __init__(self, **properties):\n    # Set Form properties and Data Bindings.\n    self.init_components(**properties)\n\n    # Any code you write here will run before the form opens.\n\n  def text_box_1_pressed_enter(self, **event_args):\n    \"\"\"This method is called when the user presses Enter in this text box\"\"\"\n    pass\n\n  def button_1_click(self, **event_args):\n    global p\n    p=anvil.server.call('predict_next_word1',self.text_area.text,self.limit_text.text)\n    self.rich_text_1.clear()\n    self.rich_text_1.content=p\n    \n  \n\n","class_name":"Form1","id":"1701423698279508675789343.181"}],"services":[{"source":"\/runtime\/services\/tables.yml","client_config":{}}]},"appId":"EPQKLGEWOQYLAQFS","appOrigin":"https:\/\/nexttwordpredictorrr.anvil.app","appStartupData":null,"ideOrigin":"https:\/\/anvil.works","runtimeVersion":3,"isCrawler":null});const loadAppAfter = window.anvil._loadAppAfter || [];loadApp.then(function() { Promise.all(loadAppAfter).then(function() {window.openForm("Form1");});});});
</script>


</body></html>